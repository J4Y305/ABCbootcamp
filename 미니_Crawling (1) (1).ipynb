{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f9b6c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.8.3-py3-none-any.whl (6.5 MB)\n",
      "     ---------------------------------------- 6.5/6.5 MB 10.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\jay\\anaconda3\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\jay\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.10.2-py3-none-any.whl (17 kB)\n",
      "Collecting trio~=0.17\n",
      "  Using cached trio-0.22.0-py3-none-any.whl (384 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jay\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Collecting async-generator>=1.9\n",
      "  Using cached async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\jay\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: idna in c:\\users\\jay\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting outcome\n",
      "  Using cached outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\jay\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\jay\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Downloading exceptiongroup-1.1.1-py3-none-any.whl (14 kB)\n",
      "Collecting wsproto>=0.14\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\jay\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\jay\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: outcome, h11, exceptiongroup, async-generator, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed async-generator-1.10 exceptiongroup-1.1.1 h11-0.14.0 outcome-1.2.0 selenium-4.8.3 trio-0.22.0 trio-websocket-0.10.2 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6985e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-3.8.6-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\jay\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.28.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\jay\\anaconda3\\lib\\site-packages (from webdriver-manager) (22.0)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jay\\anaconda3\\lib\\site-packages (from webdriver-manager) (4.64.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jay\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jay\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jay\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\jay\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\jay\\anaconda3\\lib\\site-packages (from tqdm->webdriver-manager) (0.4.6)\n",
      "Installing collected packages: python-dotenv, webdriver-manager\n",
      "Successfully installed python-dotenv-1.0.0 webdriver-manager-3.8.6\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8b2a0fe8-3ab1-4bfa-b5f4-cb0710eb0d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import math\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "path = 'chromedriver'\n",
    "excutable_path = 'chromedriver.exe'\n",
    "source_url = \"https://map.kakao.com/\"\n",
    "driver = webdriver.Chrome(executable_path=excutable_path)\n",
    "\n",
    "driver.get(source_url)\n",
    "\n",
    "search=driver.find_element(By.XPATH, '//*[@id=\"search.keyword.query\"]')\n",
    "search.send_keys(\"합정 라멘\")\n",
    "search.send_keys(Keys.ENTER)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "moreviews = soup.find_all(name=\"a\", attrs={\"class\":\"moreview\"})\n",
    "\n",
    "driver.close()\n",
    "\n",
    "urls=[]\n",
    "for i in moreviews:\n",
    "    page_url=i.get(\"href\")\n",
    "    urls.append(page_url)\n",
    "    \n",
    "ramen=urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "194971d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns = ['score', 'review']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "stars=[]\n",
    "reviews=[]\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=excutable_path)\n",
    "driver.get(ramen)\n",
    "\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "            \n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "            # 스크롤 다운 후 스크롤 높이 다시 가져옴\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "    tmp=driver.page_source\n",
    "    tmp2 = BeautifulSoup(tmp, \"html.parser\")\n",
    "    #print(int(tmp2.select('#mArticle > div.cont_evaluation > strong.total_evaluation > span')[0].get_text()))\n",
    "    total_reviews=int(tmp2.select('#mArticle > div.cont_evaluation > strong.total_evaluation > span')[0].get_text())\n",
    "    pages=math.ceil(total_reviews/5)\n",
    "    print(pages)\n",
    "    time.sleep(5)\n",
    "\n",
    "for i in range(1,pages+1):\n",
    "    t1=driver.page_source\n",
    "    t2=BeautifulSoup(t1, \"html.parser\")\n",
    "    t3=t2.find(name=\"div\", attrs={\"class\":\"evaluation_review\"})\n",
    "\n",
    "    star=t3.find_all('em',{'class':'num_rate'})\n",
    "    review=t3.find_all('p',{'class':'txt_comment'})\n",
    "\n",
    "    stars.extend(star)\n",
    "    reviews.extend(review)\n",
    "\n",
    "    i=i+1\n",
    "                \n",
    "    if i > pages:\n",
    "        break\n",
    "#     wait = WebDriverWait(driver, 10)\n",
    "#     element = wait.until(EC.presence_of_element_located((By.XPATH, \"//*[@id='mArticle']/div[7]/div[3]/a\")))\n",
    "#     element.send_keys(Keys.ENTER)\n",
    "    next_page = driver.find_element(By.XPATH, \"//*[@id='mArticle']/div[7]/div[3]/a\")\n",
    "    next_page.send_keys(Keys.ENTER)\n",
    "    time.sleep(1)\n",
    "    for s, r in zip(stars, reviews):\n",
    "        row = [s.text[0], r.find(name=\"span\").text]\n",
    "        series = pd.Series(row, index=df.columns)\n",
    "        df = df.append(series, ignore_index=True)\n",
    "    \n",
    "df.to_csv('oreno_ramen.csv',encoding='utf-8')\n",
    "driver.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "99f4ab11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "columns = ['score', 'review']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "executable_path = 'C:/chromedriver.exe' # Chrome 드라이버의 실행 파일 경로로 수정해주세요.\n",
    "\n",
    "\n",
    "\n",
    "stars = []\n",
    "reviews = []\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=executable_path)\n",
    "driver.get(ramen)\n",
    "\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "    tmp = driver.page_source\n",
    "    tmp2 = BeautifulSoup(tmp, \"html.parser\")\n",
    "    total_reviews = int(tmp2.select('#mArticle > div.cont_evaluation > strong.total_evaluation > span')[0].get_text())\n",
    "    pages = math.ceil(total_reviews / 5)\n",
    "    print(pages)\n",
    "    time.sleep(5)\n",
    "\n",
    "    for i in range(1, pages + 1):\n",
    "        t1 = driver.page_source\n",
    "        t2 = BeautifulSoup(t1, \"html.parser\")\n",
    "        t3 = t2.find(name=\"div\", attrs={\"class\": \"evaluation_review\"})\n",
    "\n",
    "        star = t3.find_all('em', {'class': 'num_rate'})\n",
    "        review = t3.find_all('p', {'class': 'txt_comment'})\n",
    "\n",
    "        stars.extend(star)\n",
    "        reviews.extend(review)\n",
    "\n",
    "        i = i + 1\n",
    "\n",
    "        if i > pages:\n",
    "            break\n",
    "\n",
    "        next_page = driver.find_element(By.XPATH, \"//*[@id='mArticle']/div[7]/div[3]/a\")\n",
    "        next_page.send_keys(Keys.ENTER)\n",
    "        time.sleep(1)\n",
    "\n",
    "for s, r in zip(stars, reviews):\n",
    "    row = [s.text[0], r.find(name=\"span\").text]\n",
    "    series = pd.Series(row, index=df.columns)\n",
    "    df = df.append(series, ignore_index=True)\n",
    "\n",
    "df.to_csv('oreno_ramen.csv', encoding='utf-8')\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5c4ad9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, score, review]\n",
       "Index: []"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('oreno_ramen.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d8de9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
